---
title: "Course Project - Exp Distributions"
output: pdf_document
---

##Introduction to the Course Project
Under Coursera and John Hopkin's University's Statistical Inference course, the course project requests that we investigate exponential distributions and verifiy that the implications from the Law of Large Numbers and Central Limit Theorem. 

##Brief Overview of Central Limit Theorem and Law of Large Numbers
In a given experiment, we would like to estimate the mean of a population ($mu$). Rather than sampling the entire population, we take subsets from population to derive sample mean. According to the Law of Large Numbers, as $n$ increases in each subset, sample mean approximates $mu$.

In the same line, Central Limit Theorem provides the following:

$$\lim{n \to infty}, sqrt(n)*(S_n - \mu)/\sigma = N(0, 1)$$

Given sampled data from any type of i.i.d distribution, as $n$ number of sample increases, when standardized, the distribution of sample mean will exhibit the shape of a standard normal distribution with mean 0 and variance 1.  

##Theoretical Mean and Variance of the Population
In this project, we take a simulated data from an exponential distribution, which is clearly not Gausssian, to show that its sample mean will approximate normal. Additionally, its mean and variance will be shown via Law of Large Numbers its quality as an unbiased estimator. With lambda set at 0.2 the distribution will have the following theoretical traits:

- Mean of Exp.Distribution ($mu$):

```{r, echo=TRUE}
MeanTHEO <- 1/0.2
```

- Variance of Exp.Distribution ($\sigma^2$): 1/$\lambda^2$ = 1/0.04 = 25

```{r, echo=TRUE}
VarTHEO <- 1/(0.2^2)
```

##Simulated vs Theoretical Mean

```{r, echo=FALSE}
library(ggplot2)
library(gridExtra)
```

```{r, echo=FALSE}
#Alternate method is to embed while loop into dat within data.frame create
#Downside is that each centrality measure like mean,var calculation is based on different sets of i.i.d sampled data  
#Different from what we will usually see in experiments
n <- 1
dat <- c()
while (n <=1000){
  dat <- rbind(dat, rexp(40, rate=0.2))
  n <- n + 1
}

zMean <- function(x, n){sqrt(n)*(mean(x) - MeanTHEO)/VarTHEO}

out <- data.frame(
  EXmean = apply(dat, 1, mean),
  EXvar = apply(dat, 1, var),
  ZSmean = apply(dat, 1, zMean, n)
)
```

```{r, echo=FALSE}
#Plot - Simulated vs Theoretical
ggplot(out, aes(x = EXmean)) +
  geom_density(statbin="identity") +
  geom_vline(xintercept=MeanTHEO, color="red", linetype="longdash") +
  geom_vline(xintercept=mean(out$EXmean), color="blue", alpha=0.6) +
  scale_y_continuous(limits=c(0,0.6), breaks=seq(0,0.6, 0.1))
```

```{r, echo=TRUE}
#Calculated - Simulated vs Theoretical
MeanTHEO
mean(out$EXmean)
```

##Simulated vs Theoretical Variance

```{r, echo=FALSE}
ggplot(out, aes(x = EXvar)) +
  geom_density(statbin="identity") +
  geom_vline(xintercept=VarTHEO, color="red", linetype="longdash") +
  geom_vline(xintercept=mean(out$EXvar), color="blue", alpha=0.6)
```

##Sampling Mean and Central Limit Theorem

```{r, echo=FALSE}
ggplot(out, aes(x = ZSmean)) +
  geom_density(statbin="identity") +
  geom_vline(xintercept=0, color="red", linetype="longdash", width=0.2) +
  geom_vline(xintercept=mean(out$ZSmean), color="blue") +
  scale_y_continuous(limits=c(0,0.6), breaks=seq(0,0.6, 0.1))
```

```{r, echo=TRUE}
mean(out$ZSmean)
var(out$ZSmean)
```
